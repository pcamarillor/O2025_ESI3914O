{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5da817f",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "\n",
    "#### <center> **Final Project: Machine Learning** </center>\n",
    "---\n",
    "\n",
    "**Date**: October, 2025\n",
    "\n",
    "**Student Name**: Luis Daniel Arellano Núñez\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d618f8f",
   "metadata": {},
   "source": [
    "## Machine Learning algorithm to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0ce77-d108-4fed-b94c-bd768b86923f",
   "metadata": {},
   "source": [
    "The problem I aim to solve is a binary classification task: predicting whether a patient has diabetes based on several clinical features. This type of problem is well-suited for supervised learning because the dataset includes labeled examples indicating whether each patient is diabetic or not. I selected Logistic Regression as the main algorithm because it is a simple yet powerful model for binary outcomes. It provides interpretable coefficients that help identify which medical factors are most associated with diabetes, and it performs well when relationships between variables and the target follow a linear trend. Additionally, Logistic Regression is computationally efficient and serves as a solid baseline for medical risk prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d720cb",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55303e45-2bc1-4dc2-b2a3-6860e93700c4",
   "metadata": {},
   "source": [
    "For this project, I am using the Diabetes Dataset available on Kaggle, which contains medical measurements used to diagnose diabetes in patients.\n",
    "\n",
    "* Source: Kaggle — Diabetes Dataset by Akshay Dattatray Khare\n",
    "\n",
    "* Size of the dataset: The dataset contains 768 rows and 9 columns, including features such as glucose level, BMI, age, insulin, and the target variable Outcome (0 = no diabetes, 1 = diabetes).\n",
    "\n",
    "Since I am working on a classification problem, I analyzed the class distribution using PySpark to determine whether the dataset is balanced. The results show that the dataset is slightly imbalanced: approximately 65% of the patients are non-diabetic (class 0) and 35% are diabetic (class 1). While not severely imbalanced, this distribution may still require attention during model evaluation to ensure the classifier performs well on both classes.\n",
    "\n",
    "link:\n",
    "\n",
    "* https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dd8dcf",
   "metadata": {},
   "source": [
    "## ML Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1602f21",
   "metadata": {},
   "source": [
    "### Proyect configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7592c533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/14 15:29:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ML: Final proyect Logistic Regression\") \\\n",
    "    .master(\"spark://4de840d3187e:7077\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"INFO\")\n",
    "\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16fc465",
   "metadata": {},
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91650e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Pregnancies: integer (nullable = true)\n",
      " |-- Glucose: integer (nullable = true)\n",
      " |-- BloodPressure: integer (nullable = true)\n",
      " |-- SkinThickness: integer (nullable = true)\n",
      " |-- Insulin: integer (nullable = true)\n",
      " |-- BMI: integer (nullable = true)\n",
      " |-- DiabetesPedigreeFunction: integer (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Outcome: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:===========================================================(1 + 0) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from Daniel_Arellano.sql_im import SparkUtils\n",
    "\n",
    "# Define schema for the DataFrame\n",
    "diab_schema = SparkUtils.generate_schema([\n",
    "    (\"Pregnancies\", \"int\"),\n",
    "    (\"Glucose\", \"int\"),\n",
    "    (\"BloodPressure\", \"int\"),\n",
    "    (\"SkinThickness\", \"int\"),\n",
    "    (\"Insulin\", \"int\"),\n",
    "    (\"BMI\", \"int\"),\n",
    "    (\"DiabetesPedigreeFunction\", \"int\"),\n",
    "    (\"Age\", \"int\"),\n",
    "    (\"Outcome\", \"int\")])\n",
    "\n",
    "# Source: https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression?resource=download\n",
    "\n",
    "diab_df = spark.read \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .schema(diab_schema) \\\n",
    "                .csv(\"/opt/spark/work-dir/data/Diabetes/diabetes.csv\")\n",
    "\n",
    "diab_df.printSchema()\n",
    "print(f\"Number of records:{diab_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cdfaca",
   "metadata": {},
   "source": [
    "### Check if dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "800f4254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|Outcome|count|\n",
      "+-------+-----+\n",
      "|      0|  500|\n",
      "|      1|  268|\n",
      "+-------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Count instances of each class\n",
    "#diab_df.groupBy(\"Outcome\").agg(count(\"*\").alias(\"count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae43e4-1133-4d56-ae8a-fb00369db59a",
   "metadata": {},
   "source": [
    "The dataset is unbalanced, so this will determine the type of variable we can rely on, in the predictions part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e861ee-8178-42c8-8a8d-b76f437df454",
   "metadata": {},
   "source": [
    "### We assemble the columns into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66aee9f3-ffef-499a-a894-551ebe961acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    1|[6.0,148.0,72.0,3...|\n",
      "|    0|[1.0,85.0,66.0,29...|\n",
      "|    1|(8,[0,1,2,7],[8.0...|\n",
      "|    0|[1.0,89.0,66.0,23...|\n",
      "|    1|[0.0,137.0,40.0,3...|\n",
      "|    0|(8,[0,1,2,7],[5.0...|\n",
      "|    1|[3.0,78.0,50.0,32...|\n",
      "|    0|(8,[0,1,7],[10.0,...|\n",
      "|    1|[2.0,197.0,70.0,4...|\n",
      "|    1|(8,[0,1,2,7],[8.0...|\n",
      "|    0|(8,[0,1,2,7],[4.0...|\n",
      "|    1|[10.0,168.0,74.0,...|\n",
      "|    0|(8,[0,1,2,7],[10....|\n",
      "|    1|[1.0,189.0,60.0,2...|\n",
      "|    1|[5.0,166.0,72.0,1...|\n",
      "|    1|(8,[0,1,5,7],[7.0...|\n",
      "|    1|[0.0,118.0,84.0,4...|\n",
      "|    1|(8,[0,1,2,7],[7.0...|\n",
      "|    0|[1.0,103.0,30.0,3...|\n",
      "|    1|[1.0,115.0,70.0,3...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "diab_df = diab_df.withColumnRenamed(\"Outcome\", \"label\")\n",
    "\n",
    "imputed_df = diab_df.fillna(0)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"], outputCol=\"features\")\n",
    "data_with_features = assembler.transform(imputed_df).select(\"label\", \"features\")\n",
    "#data_with_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f43f7c1-d6ca-4685-a589-eba18072232d",
   "metadata": {},
   "source": [
    "### Data splitting (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149389cc-dc1c-4d12-ae65-16b33272d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-----+\n",
      "|Pregnancies|Glucose|BloodPressure|SkinThickness|Insulin|BMI|DiabetesPedigreeFunction|Age|label|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-----+\n",
      "|          6|    148|           72|           35|      0|  0|                       0| 50|    1|\n",
      "|          1|     85|           66|           29|      0|  0|                       0| 31|    0|\n",
      "|          8|    183|           64|            0|      0|  0|                       0| 32|    1|\n",
      "|          1|     89|           66|           23|     94|  0|                       0| 21|    0|\n",
      "|          0|    137|           40|           35|    168|  0|                       0| 33|    1|\n",
      "|          5|    116|           74|            0|      0|  0|                       0| 30|    0|\n",
      "|          3|     78|           50|           32|     88| 31|                       0| 26|    1|\n",
      "|         10|    115|            0|            0|      0|  0|                       0| 29|    0|\n",
      "|          2|    197|           70|           45|    543|  0|                       0| 53|    1|\n",
      "|          8|    125|           96|            0|      0|  0|                       0| 54|    1|\n",
      "|          4|    110|           92|            0|      0|  0|                       0| 30|    0|\n",
      "|         10|    168|           74|            0|      0| 38|                       0| 34|    1|\n",
      "|         10|    139|           80|            0|      0|  0|                       0| 57|    0|\n",
      "|          1|    189|           60|           23|    846|  0|                       0| 59|    1|\n",
      "|          5|    166|           72|           19|    175|  0|                       0| 51|    1|\n",
      "|          7|    100|            0|            0|      0| 30|                       0| 32|    1|\n",
      "|          0|    118|           84|           47|    230|  0|                       0| 31|    1|\n",
      "|          7|    107|           74|            0|      0|  0|                       0| 31|    1|\n",
      "|          1|    103|           30|           38|     83|  0|                       0| 33|    0|\n",
      "|          1|    115|           70|           30|     96|  0|                       0| 32|    1|\n",
      "+-----------+-------+-------------+-------------+-------+---+------------------------+---+-----+\n",
      "only showing top 20 rows\n",
      "train set\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[1.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "|    0|(8,[0,1,2,7],[2.0...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = data_with_features.randomSplit([0.8, 0.2], seed=13)\n",
    "\n",
    "#Show dataset for debugging\n",
    "print(\"Original Dataset\")\n",
    "#imputed_df.show()\n",
    "\n",
    "# Print train dataset\n",
    "print(\"train set\")\n",
    "#train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2fbbb9-f394-4bed-88ae-0ebfdd31dea7",
   "metadata": {},
   "source": [
    "### Create ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c407ab33-a6b2-4e21-bc96-f9fd49302ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388eaaca-862a-4b07-9037-670d20af1eca",
   "metadata": {},
   "source": [
    "### Train ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6db9503-f888-444a-85fd-02743e2bce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/14 15:30:28 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.05255214988622757,0.014379505679704347,-0.0012754371982106045,0.005168707257162747,0.0002016958273922796,0.007144428589115499,0.0,0.011366944469557886]\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Print coefficients\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "\n",
    "# Display model summary\n",
    "training_summary = lr_model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58464b-893c-4d67-b710-c4d9faaa32ad",
   "metadata": {},
   "source": [
    "### Persist the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1668ddaa-e4c4-40b0-901e-152a44b2944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "path = \"/opt/spark/work-dir/data/mlmodels/proyect/diabetes_ml\"\n",
    "lr_model.write().overwrite().save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14db8582-e8d0-43c9-9766-fb87953e7ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  metadata\n"
     ]
    }
   ],
   "source": [
    "!ls ../../data/mlmodels/proyect/diabetes_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8dedf8",
   "metadata": {},
   "source": [
    "## ML Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5b28f-1880-4660-b2da-374b26bdcb74",
   "metadata": {},
   "source": [
    "### Predictions with the loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75602966-e8cf-4351-95e5-bab099d8cc19",
   "metadata": {},
   "source": [
    "To generate predictions, the previously trained logistic regression model is first loaded from storage using LogisticRegressionModel.load(). Once the model is available, it is applied to the test dataset through the transform() method. This method takes the feature vector for each patient and computes both the predicted class label and the probability associated with each outcome. The resulting DataFrame contains several useful columns, including the original features, the predicted class (prediction), and the model-estimated probability of having diabetes (probability). Displaying these results allows us to evaluate how well the model generalizes to unseen data and to analyze the confidence of each prediction, which is especially important in medical decision-making contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c832976f-fae7-42f1-94f2-4940d50c14ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|            features|prediction|         probability|\n",
      "+--------------------+----------+--------------------+\n",
      "|(8,[0,1,2,7],[1.0...|       0.0|[0.84737099092317...|\n",
      "|(8,[0,1,2,7],[1.0...|       0.0|[0.78754841417407...|\n",
      "|(8,[0,1,2,7],[2.0...|       0.0|[0.81437472307329...|\n",
      "|(8,[0,1,2,7],[3.0...|       0.0|[0.81035364058587...|\n",
      "|(8,[0,1,2,7],[3.0...|       0.0|[0.82548045910985...|\n",
      "|(8,[0,1,2,7],[3.0...|       0.0|[0.76707568449425...|\n",
      "|(8,[0,1,2,7],[3.0...|       0.0|[0.76649733355903...|\n",
      "|(8,[0,1,2,7],[3.0...|       0.0|[0.63683811234577...|\n",
      "|(8,[0,1,2,7],[4.0...|       0.0|[0.70058856689063...|\n",
      "|(8,[0,1,2,7],[5.0...|       0.0|[0.69547274144500...|\n",
      "|(8,[0,1,2,7],[7.0...|       0.0|[0.62053467709073...|\n",
      "|(8,[0,1,2,7],[7.0...|       0.0|[0.57653424728884...|\n",
      "|(8,[0,1,2,7],[8.0...|       0.0|[0.66558401864923...|\n",
      "|(8,[0,1,2,7],[8.0...|       0.0|[0.69891412431244...|\n",
      "|(8,[0,1,2,7],[10....|       0.0|[0.76028731231029...|\n",
      "|(8,[0,1,3,7],[2.0...|       0.0|[0.79024827927579...|\n",
      "|(8,[0,1,5,7],[4.0...|       0.0|[0.73668597943220...|\n",
      "|(8,[0,1,7],[6.0,1...|       0.0|[0.69751254511261...|\n",
      "|(8,[1,2,3,7],[108...|       0.0|[0.75991700459865...|\n",
      "|(8,[1,2,3,7],[137...|       0.0|[0.68100679204628...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegressionModel\n",
    "\n",
    "loaded_model = LogisticRegressionModel.load(path)\n",
    "\n",
    "# Use the trained model to make predictions on the test data\n",
    "predictions = loaded_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "predictions.select(\"features\", \"prediction\", \"probability\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30de6f-5215-40aa-abac-290d54aa9856",
   "metadata": {},
   "source": [
    "### Test ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9432a48c-25cd-4415-93f6-2b86d0569f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7536231884057971\n",
      "Precision: 0.7938303575484984\n",
      "Recall: 0.7536231884057971\n",
      "F1 Score: 0.7219772506040263\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
    "                            predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, \n",
    "                  {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "precision = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Recall: {recall}\")\n",
    "f1 = evaluator.evaluate(predictions,\n",
    "                {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bcca1b-c7e1-4a52-bcd1-75c1e4294884",
   "metadata": {},
   "source": [
    "Since the dataset is not balanced, relying solely on accuracy would give a misleading representation of the model’s performance. In imbalanced datasets, a classifier can achieve high accuracy simply by predicting the majority class most of the time, while still performing poorly on the minority class, which in this case represents patients diagnosed with diabetes. To address this limitation, the F1-score is used as the primary evaluation metric. The F1-score provides a better assessment by combining both precision and recall, ensuring that the model not only identifies diabetic cases correctly but also avoids missing them. This makes F1 a more reliable and informative metric for evaluating classification performance in medical prediction tasks involving class imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
