{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 05**: Data pipeline with Neo4j\n",
    "\n",
    "**Date**: October 2nd 2025\n",
    "\n",
    "**Student Name**: Francisco Delgado\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893c817",
   "metadata": {},
   "source": [
    "# Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e84c3",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed17a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /root/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /root/.ivy2.5.2/jars\n",
      "org.neo4j#neo4j-connector-apache-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d2561f40-b4de-46e9-a680-f39ffe050a9c;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#caniuse-core;1.3.0 in central\n",
      "\tfound org.neo4j#caniuse-api;1.3.0 in central\n",
      "\tfound org.jetbrains.kotlin#kotlin-stdlib;2.1.20 in central\n",
      "\tfound org.jetbrains#annotations;13.0 in central\n",
      "\tfound org.neo4j#caniuse-neo4j-detection;1.3.0 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver-slim;4.4.21 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound io.netty#netty-handler;4.1.127.Final in central\n",
      "\tfound io.netty#netty-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.127.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.127.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.73.Final in central\n",
      "\tfound io.projectreactor#reactor-core;3.6.11 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2022.11.0 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.2 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-spi;1.0.0-rc2 in central\n",
      "\tfound org.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.17 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-provided;1.0.0-rc2 in central\n",
      ":: resolution report :: resolve 968ms :: artifacts dl 32ms\n",
      "\t:: modules in use:\n",
      "\tio.netty#netty-buffer;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.73.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.127.Final from central in [default]\n",
      "\tio.projectreactor#reactor-core;3.6.11 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.2 from central in [default]\n",
      "\torg.jetbrains#annotations;13.0 from central in [default]\n",
      "\torg.jetbrains.kotlin#kotlin-stdlib;2.1.20 from central in [default]\n",
      "\torg.neo4j#caniuse-api;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-core;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-neo4j-detection;1.3.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2022.11.0 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-provided;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-spi;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver-slim;4.4.21 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.17 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   0   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d2561f40-b4de-46e9-a680-f39ffe050a9c\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/13ms)\n",
      "25/10/06 05:37:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on SparkSQL\") \\\n",
    "    .master(\"spark://9eae4bedccb3:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b6cfcc7-4c77-4aeb-a184-8283fbc8b73b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1751331892.py, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 22\u001b[0;36m\u001b[0m\n\u001b[0;31m    .option(\"header\", \"true\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from FrankModule.spark_utils import SparkUtils\n",
    "\n",
    "# === Definir esquema de las columnas ===\n",
    "schema_columns = [\n",
    "    (\"id\", \"string\"),\n",
    "    (\"name\", \"string\"),\n",
    "    (\"genre\", \"string\"),\n",
    "    (\"artists\", \"string\"),\n",
    "    (\"album\", \"string\"),\n",
    "    (\"popularity\", \"int\"),\n",
    "    (\"duration_ms\", \"long\"),\n",
    "    (\"explicit\", \"string\"),\n",
    "]\n",
    "\n",
    "songs_schema = SparkUtils.generate_schema(schema_columns)\n",
    "\n",
    "# === Ruta corregida ===\n",
    "csv_path = \"spark/notebooks/data/spotify_tracks/spotify_tracks.csv\"\n",
    "\n",
    "# === Lectura del CSV con el esquema ===\n",
    "df_songs = spark.read \\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .schema(songs_schema)\n",
    "    .csv(csv_path)\n",
    "\n",
    "\n",
    "# === Mostrar muestra ===\n",
    "df_songs.show(5, truncate=False)\n",
    "df_songs.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93cd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "csv_path = \"data/spotify_tracks/spotify_tracks.csv\"\n",
    "\n",
    "df = (spark.read\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"inferSchema\", \"true\")\n",
    "      .csv(csv_path))\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5, truncate=False)\n",
    "df.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e82d5",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000b6d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, explode, trim\n",
    "\n",
    "df_norm = (df\n",
    "    .withColumn(\"artists_list\", split(col(\"artists\"), \",\"))\n",
    ")\n",
    "\n",
    "song_artist = (df_norm\n",
    "    .withColumn(\"artist_name\", trim(explode(col(\"artists_list\"))))\n",
    "    .select(\n",
    "        col(\"id\").alias(\"song_id\"),\n",
    "        col(\"name\").alias(\"song_name\"),\n",
    "        col(\"popularity\"),\n",
    "        col(\"duration_ms\"),\n",
    "        col(\"explicit\"),\n",
    "        col(\"genre\"),\n",
    "        col(\"album\"),\n",
    "        col(\"artist_name\")\n",
    "    )\n",
    "    .dropna(subset=[\"song_id\", \"artist_name\"])\n",
    ")\n",
    "\n",
    "song_artist.show(5, truncate=False)\n",
    "song_artist.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac917428-5512-4932-a787-b909314c3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nodos de canciones\n",
    "songs_df = (song_artist\n",
    "    .select(\n",
    "        col(\"song_id\").alias(\"id\"),\n",
    "        col(\"song_name\").alias(\"name\"),\n",
    "        \"popularity\", \"duration_ms\", \"explicit\"\n",
    "    )\n",
    "    .dropDuplicates([\"id\"])\n",
    ")\n",
    "\n",
    "# Nodos de artistas\n",
    "artists_df = (song_artist\n",
    "    .select(col(\"artist_name\").alias(\"name\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates([\"name\"])\n",
    ")\n",
    "\n",
    "# (Opcional) Nodos de género\n",
    "genres_df = (song_artist\n",
    "    .select(trim(col(\"genre\")).alias(\"name\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates([\"name\"])\n",
    ")\n",
    "\n",
    "# (Opcional) Nodos de álbum\n",
    "albums_df = (song_artist\n",
    "    .select(trim(col(\"album\")).alias(\"name\"))\n",
    "    .dropna()\n",
    "    .dropDuplicates([\"name\"])\n",
    ")\n",
    "\n",
    "print(\"Songs:\", songs_df.count())\n",
    "print(\"Artists:\", artists_df.count())\n",
    "print(\"Genres:\", genres_df.count())\n",
    "print(\"Albums:\", albums_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf9a64-ab20-47b4-ab0f-fb2d82dcb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Song -[:PERFORMED_BY]-> Artist\n",
    "edges_song_artist = (song_artist\n",
    "    .select(\n",
    "        col(\"song_id\").alias(\"src_song_id\"),\n",
    "        col(\"artist_name\").alias(\"dst_artist_name\")\n",
    "    )\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "# Song -[:HAS_GENRE]-> Genre\n",
    "edges_song_genre = (song_artist\n",
    "    .select(\n",
    "        col(\"song_id\").alias(\"src_song_id\"),\n",
    "        trim(col(\"genre\")).alias(\"dst_genre_name\")\n",
    "    )\n",
    "    .dropna()\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "# Song -[:PART_OF_ALBUM]-> Album\n",
    "edges_song_album = (song_artist\n",
    "    .select(\n",
    "        col(\"song_id\").alias(\"src_song_id\"),\n",
    "        trim(col(\"album\")).alias(\"dst_album_name\")\n",
    "    )\n",
    "    .dropna()\n",
    "    .dropDuplicates()\n",
    ")\n",
    "\n",
    "print(\"E(Song->Artist):\", edges_song_artist.count())\n",
    "print(\"E(Song->Genre):\", edges_song_genre.count())\n",
    "print(\"E(Song->Album):\", edges_song_album.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a68775",
   "metadata": {},
   "source": [
    "# Writing Data in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the code to write a graph from PySpark's DataFrames to Neo4jneo4j_common = {\n",
    "    \"url\": NEO4J_URL,\n",
    "    \"database\": NEO4J_DATABASE,\n",
    "    \"authentication.type\": \"basic\",\n",
    "    \"authentication.basic.username\": NEO4J_USER,\n",
    "    \"authentication.basic.password\": NEO4J_PASSWORD,\n",
    "}\n",
    "\n",
    "# ===== NODOS =====\n",
    "(songs_df.write\n",
    " .format(\"org.neo4j.spark.DataSource\")\n",
    " .mode(\"Overwrite\")\n",
    " .options(**neo4j_common)\n",
    " .option(\"labels\", \":Song\")\n",
    " .option(\"node.keys\", \"id\")\n",
    " .save())\n",
    "\n",
    "(artists_df.write\n",
    " .format(\"org.neo4j.spark.DataSource\")\n",
    " .mode(\"Overwrite\")\n",
    " .options(**neo4j_common)\n",
    " .option(\"labels\", \":Artist\")\n",
    " .option(\"node.keys\", \"name\")\n",
    " .save())\n",
    "\n",
    "(genres_df.write\n",
    " .format(\"org.neo4j.spark.DataSource\")\n",
    " .mode(\"Overwrite\")\n",
    " .options(**neo4j_common)\n",
    " .option(\"labels\", \":Genre\")\n",
    " .option(\"node.keys\", \"name\")\n",
    " .save())\n",
    "\n",
    "(albums_df.write\n",
    " .format(\"org.neo4j.spark.DataSource\")\n",
    " .mode(\"Overwrite\")\n",
    " .options(**neo4j_common)\n",
    " .option(\"labels\", \":Album\")\n",
    " .option(\"node.keys\", \"name\")\n",
    " .save())\n",
    "\n",
    "print(\"Nodos escritos en Neo4j.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e54f34-213a-4de4-aa86-e8840dc15f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== RELACIONES =====\n",
    "\n",
    "# Song -[:PERFORMED_BY]-> Artist\n",
    "(edges_song_artist.write\n",
    " .format(\"org.neo4j.spark.DataSource\")\n",
    " .mode(\"Overwrite\")\n",
    " .options(**neo4j_common)\n",
    " .option(\"relationship\", \"PERFORMED_BY\")\n",
    " .option(\"relationship.save.strategy\", \"keys\")\n",
    " .option(\"relationship.source.labels\", \":Song\")\n",
    " .option(\"relationship.source.node.keys\", \"id:src_song_id\")\n",
    " .option(\"relationship.target.labels\", \":Artist\")\n",
    " .option(\"relationship.target.node.keys\", \"name:dst_artist_name\")\n",
    " .save())\n",
    "\n",
    "# Song -[:HAS_GENRE]-> Genre\n",
    "(edges_song_genre.write\n",
    " .format(\"org.neo4j.spark.DataSource\")\n",
    " .mode(\"Overwrite\")\n",
    " .options(**neo4j_common)\n",
    " .option(\"relationship\", \"HAS_GENRE\")\n",
    " .option(\"relationship.save.strategy\", \"keys\")\n",
    " .option(\"relationship.source.labels\", \":Song\")\n",
    " .option(\"relationship.source.node.keys\", \"id:src_song_id\")\n",
    " .option(\"relationship.target.labels\", \":Genre\")\n",
    " .option(\"relationship.target.node.keys\", \"name:dst_genre_name\")\n",
    " .save())\n",
    "\n",
    "# Song -[:PART_OF_ALBUM]-> Album\n",
    "(edges_song_album.write\n",
    " .format(\"org.neo4j.spark.DataSource\")\n",
    " .mode(\"Overwrite\")\n",
    " .options(**neo4j_common)\n",
    " .option(\"relationship\", \"PART_OF_ALBUM\")\n",
    " .option(\"relationship.save.strategy\", \"keys\")\n",
    " .option(\"relationship.source.labels\", \":Song\")\n",
    " .option(\"relationship.source.node.keys\", \"id:src_song_id\")\n",
    " .option(\"relationship.target.labels\", \":Album\")\n",
    " .option(\"relationship.target.node.keys\", \"name:dst_album_name\")\n",
    " .save())\n",
    "\n",
    "print(\"Relaciones escritas en Neo4j.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30287ea",
   "metadata": {},
   "source": [
    "# Read and Query Graphs with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca7b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo: primeras 20 relaciones Song -> Artist\n",
    "query = \"\"\"\n",
    "MATCH (s:Song)-[r:PERFORMED_BY]->(a:Artist)\n",
    "RETURN s.id AS song_id, a.name AS artist, type(r) AS rel\n",
    "LIMIT 20\n",
    "\"\"\"\n",
    "\n",
    "df_cypher = (spark.read\n",
    "    .format(\"org.neo4j.spark.DataSource\")\n",
    "    .options(**neo4j_common)\n",
    "    .option(\"query\", query)\n",
    "    .load())\n",
    "\n",
    "df_cypher.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e09ed17d-deb7-424a-97d1-118b74f1ede6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Top 10 artistas por # de canciones\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query_top_artists \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mMATCH (s:Song)-[:PERFORMED_BY]->(a:Artist)\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mRETURN a.name AS artist, count(*) AS songs\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mORDER BY songs DESC\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mLIMIT 10\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m top_artists \u001b[38;5;241m=\u001b[39m (\u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.neo4j.spark.DataSource\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mneo4j_common)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, query_top_artists)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;241m.\u001b[39mload())\n\u001b[1;32m     14\u001b[0m top_artists\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "# Top 10 artistas por # de canciones\n",
    "query_top_artists = \"\"\"\n",
    "MATCH (s:Song)-[:PERFORMED_BY]->(a:Artist)\n",
    "RETURN a.name AS artist, count(*) AS songs\n",
    "ORDER BY songs DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "top_artists = (spark.read\n",
    "    .format(\"org.neo4j.spark.DataSource\")\n",
    "    .options(**neo4j_common)\n",
    "    .option(\"query\", query_top_artists)\n",
    "    .load())\n",
    "\n",
    "top_artists.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
