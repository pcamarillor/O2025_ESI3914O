{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bbcd603-0603-4739-a4ac-f6e8946cd455",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Lab 06**: Writing data in Neo4j\n",
    "\n",
    "**Date**: September 23rd 2025\n",
    "\n",
    "**Student Name**: Jose Angel Leon Perez\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa6af93-61d1-49d8-a1d0-e611f05ca7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /root/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /root/.ivy2.5.2/jars\n",
      "org.neo4j#neo4j-connector-apache-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-3a805096-62c0-4b7f-9504-7ae1fb561ea1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#caniuse-core;1.3.0 in central\n",
      "\tfound org.neo4j#caniuse-api;1.3.0 in central\n",
      "\tfound org.jetbrains.kotlin#kotlin-stdlib;2.1.20 in central\n",
      "\tfound org.jetbrains#annotations;13.0 in central\n",
      "\tfound org.neo4j#caniuse-neo4j-detection;1.3.0 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver-slim;4.4.21 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound io.netty#netty-handler;4.1.127.Final in central\n",
      "\tfound io.netty#netty-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.127.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.127.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.73.Final in central\n",
      "\tfound io.projectreactor#reactor-core;3.6.11 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2022.11.0 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.2 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-spi;1.0.0-rc2 in central\n",
      "\tfound org.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.17 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-provided;1.0.0-rc2 in central\n",
      ":: resolution report :: resolve 1036ms :: artifacts dl 22ms\n",
      "\t:: modules in use:\n",
      "\tio.netty#netty-buffer;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.73.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.127.Final from central in [default]\n",
      "\tio.projectreactor#reactor-core;3.6.11 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.2 from central in [default]\n",
      "\torg.jetbrains#annotations;13.0 from central in [default]\n",
      "\torg.jetbrains.kotlin#kotlin-stdlib;2.1.20 from central in [default]\n",
      "\torg.neo4j#caniuse-api;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-core;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-neo4j-detection;1.3.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2022.11.0 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-provided;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-spi;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver-slim;4.4.21 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.17 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   0   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-3a805096-62c0-4b7f-9504-7ae1fb561ea1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/11ms)\n",
      "25/10/06 02:25:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on storage solutions with Neo4j\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "# Optimization (reduce the number of shuffle partitions)\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615c188-17ef-4ae6-a77f-901a553d073e",
   "metadata": {},
   "source": [
    "Dataset: Select a dataset in any public repository (e.g. Kaggle or Network Repository) containing relationships. In this section of the Notebook, you need to describe nodes and edges of the graph (a column representing the sourceand another column representing the destination of the relationships).\n",
    "\n",
    "Dataset\n",
    "Descripción\n",
    "\n",
    "El dataset friends_table.csv contiene relaciones entre usuarios representados por identificadores numéricos.\n",
    "Cada fila representa una relación de amistad entre dos nodos (usuarios):\n",
    "\n",
    "Friend 1\tFriend 2\n",
    "1\t555\n",
    "1\t921\n",
    "1\t213\n",
    "2\t752\n",
    "3\t705\n",
    "...\t...\n",
    "\n",
    "Nodos (nodes_df) → los IDs únicos de usuarios.\n",
    "\n",
    "Aristas (edges_df) → las relaciones (Friend 1, Friend 2) entre ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfac5aa5-d7ad-4416-b870-546ae80d823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Ingestion: This section should contain a code cell using PySpark to read the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b251dfc-0cd1-42ce-8439-0db5bb4d24ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vista previa del dataset:\n",
      "+--------+--------+\n",
      "|Friend 1|Friend 2|\n",
      "+--------+--------+\n",
      "|       1|     555|\n",
      "|       1|     921|\n",
      "|       1|     213|\n",
      "|       1|     184|\n",
      "|       1|     242|\n",
      "|       1|     402|\n",
      "|       1|     399|\n",
      "|       1|      84|\n",
      "|       1|      55|\n",
      "|       2|     752|\n",
      "+--------+--------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/opt/spark/work-dir/friends_table.csv\", header=True, inferSchema=True)\n",
    "\n",
    "print(\"Vista previa del dataset:\")\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d682b82d-121c-4ba6-8f2d-546aa936f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformations: This section should contain a code cell using PySpark transformations to generate (at least) two DataFrames: one for nodes and one for edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da108f5-9990-4f99-94ce-39b5cb7a74b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de nodos: 1000\n",
      "Total de aristas: 9402\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|535|\n",
      "| 71|\n",
      "|705|\n",
      "|744|\n",
      "|679|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "+------+------+\n",
      "|source|target|\n",
      "+------+------+\n",
      "|     1|   555|\n",
      "|     1|   921|\n",
      "|     1|   213|\n",
      "|     1|   184|\n",
      "|     1|   242|\n",
      "+------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "edges_df = df.withColumnRenamed(\"Friend 1\", \"source\") \\\n",
    "             .withColumnRenamed(\"Friend 2\", \"target\")\n",
    "\n",
    "nodes_df = edges_df.select(col(\"source\").alias(\"id\")).union(\n",
    "           edges_df.select(col(\"target\").alias(\"id\"))\n",
    "          ).distinct()\n",
    "\n",
    "print(f\"Total de nodos: {nodes_df.count()}\")\n",
    "print(f\"Total de aristas: {edges_df.count()}\")\n",
    "\n",
    "nodes_df.show(5)\n",
    "edges_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead26df4-da7c-4a60-9cb5-ef99542bfa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "Writing Data in Neo4j: This section should contain code to persist nodes and edges DataFrames in Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b5c5a61-d03c-4c9d-a0b5-bc110d356be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodos guardados en Neo4j correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relaciones guardadas en Neo4j correctamente.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "neo4j_url = \"bolt://neo4j-iteso:7687\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_passwd = \"neo4j@1234\"\n",
    "\n",
    "\n",
    "nodes_df.write \\\n",
    "    .format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"url\", neo4j_url) \\\n",
    "    .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "    .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "    .option(\"labels\", \":Person\") \\\n",
    "    .option(\"node.keys\", \"id\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"Nodos guardados en Neo4j correctamente.\")\n",
    "\n",
    "\n",
    "edges_df.write \\\n",
    "    .format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .mode(\"Overwrite\") \\\n",
    "    .option(\"url\", neo4j_url) \\\n",
    "    .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "    .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "    .option(\"relationship\", \"FRIEND_WITH\") \\\n",
    "    .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "    .option(\"relationship.source.labels\", \":Person\") \\\n",
    "    .option(\"relationship.source.save.mode\", \"match\") \\\n",
    "    .option(\"relationship.source.node.keys\", \"source:id\") \\\n",
    "    .option(\"relationship.target.labels\", \":Person\") \\\n",
    "    .option(\"relationship.target.save.mode\", \"match\") \\\n",
    "    .option(\"relationship.target.node.keys\", \"target:id\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"Relaciones guardadas en Neo4j correctamente.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f3bb1-34bf-4ad2-9032-f4639eaafbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Querying the Graph: This section should contain code to read the graph from Neo4j and query data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8859c049-b75c-4a4d-b22d-bc10b1726170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Relaciones importadas desde Neo4j:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|source|target|\n",
      "+------+------+\n",
      "|801   |535   |\n",
      "|942   |535   |\n",
      "|796   |535   |\n",
      "|687   |535   |\n",
      "|848   |535   |\n",
      "|887   |535   |\n",
      "|146   |535   |\n",
      "|206   |535   |\n",
      "|2     |535   |\n",
      "|558   |71    |\n",
      "+------+------+\n",
      "only showing top 10 rows\n",
      "👥 Amigos del nodo 1:\n",
      "+---------+\n",
      "|friend_id|\n",
      "+---------+\n",
      "|55       |\n",
      "|84       |\n",
      "|399      |\n",
      "|402      |\n",
      "|242      |\n",
      "|184      |\n",
      "|213      |\n",
      "|921      |\n",
      "|555      |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cypher_all_df = spark.read \\\n",
    "    .format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", neo4j_url) \\\n",
    "    .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "    .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "    .option(\"query\",\n",
    "            \"\"\"\n",
    "            MATCH (a:Person)-[r:FRIEND_WITH]->(b:Person)\n",
    "            RETURN a.id AS source, b.id AS target\n",
    "            \"\"\") \\\n",
    "    .load()\n",
    "\n",
    "print(\"Relaciones importadas desde Neo4j:\")\n",
    "cypher_all_df.show(10, truncate=False)\n",
    "\n",
    "node_id = 1\n",
    "\n",
    "cypher_friends_df = spark.read \\\n",
    "    .format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", neo4j_url) \\\n",
    "    .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "    .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "    .option(\"query\",\n",
    "            f\"\"\"\n",
    "            MATCH (p1:Person {{id: {node_id}}})-[:FRIEND_WITH]->(p2:Person)\n",
    "            RETURN p2.id AS friend_id\n",
    "            \"\"\") \\\n",
    "    .load()\n",
    "\n",
    "print(f\"Amigos del nodo {node_id}:\")\n",
    "cypher_friends_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5c660-a6d0-490d-b40c-29c8c6012132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
