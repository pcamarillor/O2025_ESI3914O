{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 05**: Data pipeline with Neo4j\n",
    "\n",
    "**Date**: October 2nd 2025\n",
    "\n",
    "**Student Name**: Ivan Estrella\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893c817",
   "metadata": {},
   "source": [
    "# Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555ed0d-d1b5-427b-8026-445f4235dc6c",
   "metadata": {},
   "source": [
    "This dataset contains information about a Stack Overflow technology tag network.\n",
    "The nodes are technology tags (such as Python, JavaScript, or React) that appear in developer stories, and the edges represent co-occurrences of these tags.\n",
    "\n",
    "Link for dataset: https://www.kaggle.com/datasets/stackoverflow/stack-overflow-tag-network?select=stack_network_links.csv\n",
    "\n",
    "Neccesary files: 2 csv(links and nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e84c3",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed17a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Examples on SparkSQL\") \\\n",
    "    .master(\"spark://e3b502141eaf:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a93cd621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+--------+\n",
      "|name     |group|nodesize|\n",
      "+---------+-----+--------+\n",
      "|html     |6    |272.45  |\n",
      "|css      |6    |341.17  |\n",
      "|hibernate|8    |29.83   |\n",
      "|spring   |8    |52.84   |\n",
      "|ruby     |3    |70.14   |\n",
      "+---------+-----+--------+\n",
      "only showing top 5 rows\n",
      "+----------------+------+---------+\n",
      "|source          |target|value    |\n",
      "+----------------+------+---------+\n",
      "|azure           |.net  |20.933193|\n",
      "|sql-server      |.net  |32.322525|\n",
      "|asp.net         |.net  |48.40703 |\n",
      "|entity-framework|.net  |24.370903|\n",
      "|wpf             |.net  |32.350925|\n",
      "+----------------+------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Build schema\n",
    "# Import your module\n",
    "from IvanE.SparkUtilsIvan import SparkUtils\n",
    "from pyspark.sql.functions import regexp_replace, split, col\n",
    "\n",
    "nodes_schema = SparkUtils.generate_schema([\n",
    "    (\"name\", \"string\"),\n",
    "    (\"group\", \"int\"),\n",
    "    (\"nodesize\", \"float\")\n",
    "])\n",
    "\n",
    "df_nodes = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(nodes_schema) \\\n",
    "    .csv(\"/opt/spark/work-dir/data/lab06neo/nodes\")\n",
    "\n",
    "df_nodes.show(5, truncate=False)\n",
    "\n",
    "links_schema = SparkUtils.generate_schema([\n",
    "    (\"source\", \"string\"),\n",
    "    (\"target\", \"string\"),\n",
    "    (\"value\", \"float\")\n",
    "])\n",
    "\n",
    "df_links = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(links_schema) \\\n",
    "    .csv(\"/opt/spark/work-dir/data/lab06neo/links\")\n",
    "df_links.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372e82d5",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "000b6d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "|id    |group|size  |\n",
      "+------+-----+------+\n",
      "|spring|8    |52.84 |\n",
      "|jquery|6    |208.29|\n",
      "|mysql |6    |165.43|\n",
      "|.net  |2    |75.08 |\n",
      "|less  |6    |9.73  |\n",
      "+------+-----+------+\n",
      "only showing top 5 rows\n",
      "+-----------------+--------------+---------+\n",
      "|src              |dst           |weight   |\n",
      "+-----------------+--------------+---------+\n",
      "|android          |android-studio|33.661083|\n",
      "|typescript       |angular       |31.036482|\n",
      "|typescript       |angular2      |38.879982|\n",
      "|twitter-bootstrap|angularjs     |24.153687|\n",
      "|express          |angularjs     |24.433828|\n",
      "+-----------------+--------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Add the code for your transformations to create nodes and edges DataFrames HERE\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "tech_nodes = df_nodes.select(\n",
    "    col(\"name\").alias(\"id\"),      \n",
    "    col(\"group\"),                \n",
    "    col(\"nodesize\").alias(\"size\") \n",
    ").dropDuplicates([\"id\"])          \n",
    "\n",
    "tech_nodes.show(5, truncate=False)\n",
    "\n",
    "\n",
    "tech_edges = df_links.select(\n",
    "    col(\"source\").alias(\"src\"),  \n",
    "    col(\"target\").alias(\"dst\"),  \n",
    "    col(\"value\").alias(\"weight\")  \n",
    ").dropDuplicates()\n",
    "\n",
    "tech_edges.show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a68775",
   "metadata": {},
   "source": [
    "# Writing Data in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d01d7a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 users wrote in Neo4j\n",
      "490 edges written to Neo4j\n"
     ]
    }
   ],
   "source": [
    "# Add the code to write a graph from PySpark's DataFrames to Neo4j\n",
    "neo4j_url = \"bolt://neo4j-iteso:7687\"\n",
    "neo4j_user = \"neo4j\"\n",
    "neo4j_passwd = \"neo4j@1234\"\n",
    "\n",
    "# Nodes\n",
    "tech_nodes.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"labels\", \":Tech\") \\\n",
    "  .option(\"node.keys\", \"id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{tech_nodes.count()} users wrote in Neo4j\")\n",
    "\n",
    "# Edges\n",
    "tech_edges.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "  .option(\"relationship\", \"CO_OCCURS\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Tech\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"src:id\") \\\n",
    "  .option(\"relationship.target.labels\", \":Tech\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"dst:id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{tech_edges.count()} edges written to Neo4j\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30287ea",
   "metadata": {},
   "source": [
    "# Read and Query Graphs with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03ca7b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------------------+\n",
      "|source_tag|target_tag         |cooccurrence      |\n",
      "+----------+-------------------+------------------+\n",
      "|azure     |amazon-web-services|21.30994987487793 |\n",
      "|azure     |asp.net-web-api    |21.585695266723633|\n",
      "|azure     |.net               |20.93319320678711 |\n",
      "|azure     |c#                 |22.144487380981445|\n",
      "|azure     |asp.net            |23.76407241821289 |\n",
      "+----------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cypher_df = spark.read \\\n",
    "    .format(\"org.neo4j.spark.DataSource\") \\\n",
    "    .option(\"url\", neo4j_url) \\\n",
    "    .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "    .option(\"authentication.basic.password\", neo4j_passwd) \\\n",
    "    .option(\"query\",\n",
    "            \"\"\"\n",
    "            MATCH (t1:Tech)-[r:CO_OCCURS]->(t2:Tech)\n",
    "            WHERE t1.id = 'azure'\n",
    "            WITH t1, t2, r.weight AS cooccurrence\n",
    "            RETURN t1.id AS source_tag, t2.id AS target_tag, cooccurrence\n",
    "            \"\"\") \\\n",
    "    .load()\n",
    "\n",
    "cypher_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
