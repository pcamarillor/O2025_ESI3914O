{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92d9622",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> Computer Systems Engineering  </center>\n",
    "---\n",
    "### <center> Big Data Processing </center>\n",
    "---\n",
    "#### <center> **Autumn 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 06**: Writing Data in Neo4j\n",
    "\n",
    "**Date**: October 5 2025\n",
    "\n",
    "**Student Name**: Andre Jair Sanchez Contreras\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893c817",
   "metadata": {},
   "source": [
    "# Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68f102-d2f3-4dca-bf59-4dc37872ecf1",
   "metadata": {},
   "source": [
    "I chose this dataset because I find the structure of Amazon datasets very interesting. They are very large and provide a lot of information. Obviously, for this lab, I chose a small one with 250 customer order datasets to conduct the lab.\n",
    "this dataset contains information from the following columns:\n",
    "Order ID - Unique identifier for each order (e.g., ORD0001).\n",
    "\n",
    "Date - Date of the order.\n",
    "\n",
    "Product - Name of the product purchased.\n",
    "\n",
    "Category - Product category (Electronics, Clothing, Home Appliances, etc.).\n",
    "\n",
    "Price - Price of a single unit of the product.\n",
    "\n",
    "Quantity - Number of units purchased in the order.\n",
    "\n",
    "Total Sales - Total revenue from the order (Price × Quantity).\n",
    "\n",
    "Customer Name - Name of the customer.\n",
    "\n",
    "Customer Location - City where the customer is based.\n",
    "\n",
    "Payment Method - Mode of payment (Credit Card, Debit Card, PayPal, etc.).\n",
    "\n",
    "Status - Order status (Completed, Pending, or Cancelled). \n",
    "\n",
    "Link:https://www.kaggle.com/datasets/zahidmughal2343/amazon-sales-2025?select=amazon_sales_data+2025.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e84c3",
   "metadata": {},
   "source": [
    "# Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed17a0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /root/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /root/.ivy2.5.2/jars\n",
      "org.neo4j#neo4j-connector-apache-spark_2.13 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-134f1854-6197-40f7-9980-19d880bb83f4;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 in central\n",
      "\tfound org.neo4j#caniuse-core;1.3.0 in central\n",
      "\tfound org.neo4j#caniuse-api;1.3.0 in central\n",
      "\tfound org.jetbrains.kotlin#kotlin-stdlib;2.1.20 in central\n",
      "\tfound org.jetbrains#annotations;13.0 in central\n",
      "\tfound org.neo4j#caniuse-neo4j-detection;1.3.0 in central\n",
      "\tfound org.neo4j.driver#neo4j-java-driver-slim;4.4.21 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.4 in central\n",
      "\tfound io.netty#netty-handler;4.1.127.Final in central\n",
      "\tfound io.netty#netty-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-resolver;4.1.127.Final in central\n",
      "\tfound io.netty#netty-buffer;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport;4.1.127.Final in central\n",
      "\tfound io.netty#netty-transport-native-unix-common;4.1.127.Final in central\n",
      "\tfound io.netty#netty-codec;4.1.127.Final in central\n",
      "\tfound io.netty#netty-tcnative-classes;2.0.73.Final in central\n",
      "\tfound io.projectreactor#reactor-core;3.6.11 in central\n",
      "\tfound org.neo4j#neo4j-cypher-dsl;2022.11.0 in central\n",
      "\tfound org.apiguardian#apiguardian-api;1.1.2 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-spi;1.0.0-rc2 in central\n",
      "\tfound org.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.17 in central\n",
      "\tfound org.neo4j.connectors#commons-authn-provided;1.0.0-rc2 in central\n",
      ":: resolution report :: resolve 1429ms :: artifacts dl 49ms\n",
      "\t:: modules in use:\n",
      "\tio.netty#netty-buffer;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-codec;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-common;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-handler;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-resolver;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-tcnative-classes;2.0.73.Final from central in [default]\n",
      "\tio.netty#netty-transport;4.1.127.Final from central in [default]\n",
      "\tio.netty#netty-transport-native-unix-common;4.1.127.Final from central in [default]\n",
      "\tio.projectreactor#reactor-core;3.6.11 from central in [default]\n",
      "\torg.apiguardian#apiguardian-api;1.1.2 from central in [default]\n",
      "\torg.jetbrains#annotations;13.0 from central in [default]\n",
      "\torg.jetbrains.kotlin#kotlin-stdlib;2.1.20 from central in [default]\n",
      "\torg.neo4j#caniuse-api;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-core;1.3.0 from central in [default]\n",
      "\torg.neo4j#caniuse-neo4j-detection;1.3.0 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-connector-apache-spark_2.13_common;5.3.10_for_spark_3 from central in [default]\n",
      "\torg.neo4j#neo4j-cypher-dsl;2022.11.0 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-provided;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-authn-spi;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.connectors#commons-reauth-driver;1.0.0-rc2 from central in [default]\n",
      "\torg.neo4j.driver#neo4j-java-driver-slim;4.4.21 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.4 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.17 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   24  |   0   |   0   |   0   ||   24  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-134f1854-6197-40f7-9980-19d880bb83f4\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 24 already retrieved (0kB/31ms)\n",
      "25/10/06 06:38:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "USE_LOCAL = True  \n",
    "\n",
    "neo4j_pkg = \"org.neo4j:neo4j-connector-apache-spark_2.13:5.3.10_for_spark_3\"\n",
    "\n",
    "if USE_LOCAL:\n",
    "    \n",
    "    spark = (SparkSession.builder\n",
    "        .appName(\"Amazon → Neo4j (LOCAL)\")\n",
    "        .master(\"local[*]\")                         \n",
    "        .config(\"spark.jars.packages\", neo4j_pkg)   \n",
    "        .config(\"spark.ui.port\", \"4040\")\n",
    "        .getOrCreate())\n",
    "else:\n",
    "    \n",
    "    spark = (SparkSession.builder\n",
    "        .appName(\"Amazon → Neo4j (CLUSTER)\")\n",
    "        .master(\"spark://spark-master:7077\")\n",
    "        .config(\"spark.jars.packages\", neo4j_pkg)\n",
    "        .config(\"spark.ui.port\", \"4040\")\n",
    "        .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dffaaac1-8e71-4183-b03f-bfe88c20cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-----------+-----+--------+-----------+-------------+-------------+-----------+---------+\n",
      "|order_id|product      |category   |price|quantity|total_sales|customer_name|city         |payment    |status   |\n",
      "+--------+-------------+-----------+-----+--------+-----------+-------------+-------------+-----------+---------+\n",
      "|ORD0001 |Running Shoes|Footwear   |60.0 |3       |180.0      |Emma Clark   |New York     |Debit Card |Cancelled|\n",
      "|ORD0002 |Headphones   |Electronics|100.0|4       |400.0      |Emily Johnson|San Francisco|Debit Card |Pending  |\n",
      "|ORD0003 |Running Shoes|Footwear   |60.0 |2       |120.0      |John Doe     |Denver       |Amazon Pay |Cancelled|\n",
      "|ORD0004 |Running Shoes|Footwear   |60.0 |3       |180.0      |Olivia Wilson|Dallas       |Credit Card|Pending  |\n",
      "|ORD0005 |Smartwatch   |Electronics|150.0|3       |450.0      |Emma Clark   |New York     |Debit Card |Pending  |\n",
      "+--------+-------------+-----------+-----+--------+-----------+-------------+-------------+-----------+---------+\n",
      "only showing top 5 rows\n",
      "root\n",
      " |-- order_id: string (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- total_sales: double (nullable = true)\n",
      " |-- customer_name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- payment: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pcamarillor.spark_utils import SparkUtils\n",
    "\n",
    "schema = SparkUtils.generate_schema([\n",
    "    (\"Order ID\", \"string\"),\n",
    "    (\"Date\", \"string\"),              \n",
    "    (\"Product\", \"string\"),\n",
    "    (\"Category\", \"string\"),\n",
    "    (\"Price\", \"double\"),\n",
    "    (\"Quantity\", \"int\"),\n",
    "    (\"Total Sales\", \"double\"),\n",
    "    (\"Customer Name\", \"string\"),\n",
    "    (\"Customer Location\", \"string\"),\n",
    "    (\"Payment Method\", \"string\"),\n",
    "    (\"Status\", \"string\"),\n",
    "])\n",
    "\n",
    "csv_path = \"/opt/spark/work-dir/data/Amazon/amazon_sales_data_2025.csv\"\n",
    "\n",
    "df_raw = (spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .schema(schema)\n",
    "    .csv(csv_path))\n",
    "\n",
    "df = df_raw.selectExpr(\n",
    "    \"`Order ID`          as order_id\",\n",
    "    \"Product             as product\",\n",
    "    \"Category            as category\",\n",
    "    \"Price               as price\",\n",
    "    \"Quantity            as quantity\",\n",
    "    \"`Total Sales`       as total_sales\",\n",
    "    \"`Customer Name`     as customer_name\",\n",
    "    \"`Customer Location` as city\",\n",
    "    \"`Payment Method`    as payment\",\n",
    "    \"Status              as status\"\n",
    ")\n",
    "\n",
    "df.show(5, False)\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26263b-562a-4736-b28a-75115b5e26d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "372e82d5",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "000b6d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------+-------------+-----------+\n",
      "|customer_id                                                     |name         |city       |\n",
      "+----------------------------------------------------------------+-------------+-----------+\n",
      "|04849a78e8e956f1cf1b8a6f774f351ec5d9266d5dd34cee5c180daba6f4eb47|Olivia Wilson|Chicago    |\n",
      "|072f68ad17fe33c3b02eac04ebe844f11e830b1232c8eb3b355c9b2055b996a5|Jane Smith   |Los Angeles|\n",
      "|07758a51dc0f7fac61534c6fee7453994165100f15f05c613a5d87141248b285|Daniel Harris|Houston    |\n",
      "+----------------------------------------------------------------+-------------+-----------+\n",
      "only showing top 3 rows\n",
      "+----------------------------------------------------------------+-------+\n",
      "|city_id                                                         |name   |\n",
      "+----------------------------------------------------------------+-------+\n",
      "|fcdeb8c07d4a0e1d3b453067c2e819ba1caaf77a2a8a4acd990746e1bf242ec6|Denver |\n",
      "|4eb1b68df1329b7210000f099b011ce2eb2e9c8d5fa638ae712b91a5c078d3e5|Dallas |\n",
      "|0f5d983d203189bbffc5f686d01f6680bc6a83718a515fe42639347efc92478e|Chicago|\n",
      "+----------------------------------------------------------------+-------+\n",
      "only showing top 3 rows\n",
      "+----------------------------------------------------------------+---------------+---------------+-----+\n",
      "|product_id                                                      |name           |category       |price|\n",
      "+----------------------------------------------------------------+---------------+---------------+-----+\n",
      "|3e30ab5774792791aba7d82f27a0ad55135d325c484f4bae9ffea88b8190bcf9|Laptop         |Electronics    |800.0|\n",
      "|73b509439632dc713b5fa6a541e3b9bb13b7edb2c9782953da0391bca9fde308|Washing Machine|Home Appliances|600.0|\n",
      "|836252b68d7a338dded2dc8d370c52875fe72fb426853d3c1b29b046e28e7b96|Smartphone     |Electronics    |500.0|\n",
      "+----------------------------------------------------------------+---------------+---------------+-----+\n",
      "only showing top 3 rows\n",
      "+--------+---------+-----------+--------+\n",
      "|order_id|status   |total_sales|quantity|\n",
      "+--------+---------+-----------+--------+\n",
      "|ORD0001 |Cancelled|180.0      |3       |\n",
      "|ORD0002 |Pending  |400.0      |4       |\n",
      "|ORD0003 |Cancelled|120.0      |2       |\n",
      "+--------+---------+-----------+--------+\n",
      "only showing top 3 rows\n",
      "+----------------------------------------------------------------+-----------+\n",
      "|payment_id                                                      |name       |\n",
      "+----------------------------------------------------------------+-----------+\n",
      "|944e278918a23d481ce71ac25afe99fcf48d2ee23c34a8179f7c176546fc31ca|Debit Card |\n",
      "|9f629f57b7d02936a8bba2109b167e7083f80d99d04eacc51f16b3b0adad1c86|Credit Card|\n",
      "|4095ee39c371a037561c0985cb22a9f0c3f95f5a2de205b218a591bb082d29ef|Amazon Pay |\n",
      "+----------------------------------------------------------------+-----------+\n",
      "only showing top 3 rows\n",
      "+----------------------------------------------------------------+--------+\n",
      "|customer_id                                                     |order_id|\n",
      "+----------------------------------------------------------------+--------+\n",
      "|a4e71d7d96e77915470115aa6ca46691961811a17fb449969761143ce28c399d|ORD0009 |\n",
      "|7affcd3bcf0cc6e09b39132eae78b238141eeb01c6c3ec871c37e3a8994d4684|ORD0016 |\n",
      "|b5f91d9afad831e90e4e89f6d80954159a04ffd27de8dc90dc4fd749a865ccba|ORD0030 |\n",
      "+----------------------------------------------------------------+--------+\n",
      "only showing top 3 rows\n",
      "+--------+----------------------------------------------------------------+---+\n",
      "|order_id|product_id                                                      |qty|\n",
      "+--------+----------------------------------------------------------------+---+\n",
      "|ORD0001 |93f733d6612cd58810f546bef88264f468966cad52ac28315c7f3e779a44f5c2|3  |\n",
      "|ORD0002 |bb6eff89fe24f6d34c56ff96052440fcaa2063ebc3c22b8c70825c1039a56015|4  |\n",
      "|ORD0003 |93f733d6612cd58810f546bef88264f468966cad52ac28315c7f3e779a44f5c2|2  |\n",
      "+--------+----------------------------------------------------------------+---+\n",
      "only showing top 3 rows\n",
      "+--------+----------------------------------------------------------------+\n",
      "|order_id|payment_id                                                      |\n",
      "+--------+----------------------------------------------------------------+\n",
      "|ORD0007 |ab8a4f6bb84d161b3622afe130be97ddfa367e1b8707e49e5437a0b87ba1ae55|\n",
      "|ORD0008 |ab8a4f6bb84d161b3622afe130be97ddfa367e1b8707e49e5437a0b87ba1ae55|\n",
      "|ORD0010 |9f629f57b7d02936a8bba2109b167e7083f80d99d04eacc51f16b3b0adad1c86|\n",
      "+--------+----------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "+----------------------------------------------------------------+----------------------------------------------------------------+\n",
      "|customer_id                                                     |city_id                                                         |\n",
      "+----------------------------------------------------------------+----------------------------------------------------------------+\n",
      "|04849a78e8e956f1cf1b8a6f774f351ec5d9266d5dd34cee5c180daba6f4eb47|0f5d983d203189bbffc5f686d01f6680bc6a83718a515fe42639347efc92478e|\n",
      "|072f68ad17fe33c3b02eac04ebe844f11e830b1232c8eb3b355c9b2055b996a5|8b6e04947230473368190a71c95399a7e9a0c12faa28b04a2dd5a1cc4350a9a9|\n",
      "|07758a51dc0f7fac61534c6fee7453994165100f15f05c613a5d87141248b285|00cc7d9b5e8b01238856bf7f9d2c5bb12313bbe47f9f612374db95f0f30519ac|\n",
      "+----------------------------------------------------------------+----------------------------------------------------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Add the code for your transformations to create nodes and edges DataFrames HERE\n",
    "\n",
    "from pyspark.sql import functions as X\n",
    "\n",
    "\n",
    "def hcol(*cols):\n",
    "    return X.sha2(X.concat_ws(\"|\", *cols), 256)\n",
    "\n",
    "# --- NODES ---\n",
    "customer_nodes = (df\n",
    "    .select(\n",
    "        hcol(\"customer_name\",\"city\").alias(\"customer_id\"),\n",
    "        X.col(\"customer_name\").alias(\"name\"),\n",
    "        X.col(\"city\")\n",
    "    )\n",
    "    .dropDuplicates([\"customer_id\"])\n",
    ")\n",
    "customer_nodes.show(3, False)\n",
    "\n",
    "city_nodes = (df\n",
    "    .select(F.col(\"city\").alias(\"name\"))\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"city_id\", F.sha2(\"name\", 256))\n",
    "    .select(\"city_id\",\"name\")\n",
    ")\n",
    "city_nodes.show(3, False)\n",
    "\n",
    "product_nodes = (df\n",
    "    .select(\n",
    "        hcol(\"product\",\"category\").alias(\"product_id\"),\n",
    "        X.col(\"product\").alias(\"name\"),\n",
    "        X.col(\"category\"),\n",
    "        X.col(\"price\").cast(\"double\").alias(\"price\")\n",
    "    )\n",
    "    .dropDuplicates([\"product_id\"])\n",
    ")\n",
    "product_nodes.show(3, False)\n",
    "\n",
    "order_nodes = (df\n",
    "    .select(\n",
    "        X.col(\"order_id\"),\n",
    "        X.col(\"status\"),\n",
    "        X.col(\"total_sales\").cast(\"double\").alias(\"total_sales\"),\n",
    "        X.col(\"quantity\").cast(\"int\").alias(\"quantity\")\n",
    "    )\n",
    "    .dropDuplicates([\"order_id\"])\n",
    ")\n",
    "order_nodes.show(3, False)\n",
    "\n",
    "payment_nodes = (df\n",
    "    .select(X.col(\"payment\").alias(\"name\"))\n",
    "    .dropDuplicates()\n",
    "    .withColumn(\"payment_id\", X.sha2(\"name\",256))\n",
    "    .select(\"payment_id\",\"name\")\n",
    ")\n",
    "payment_nodes.show(3, False)\n",
    "\n",
    "# --- EDGES ---\n",
    "#Customer -> Order\n",
    "placed_edges = (df\n",
    "    .select(\n",
    "        hcol(\"customer_name\",\"city\").alias(\"customer_id\"),\n",
    "        X.col(\"order_id\")\n",
    "    )\n",
    "    .dropDuplicates()\n",
    ")\n",
    "placed_edges.show(3, False)\n",
    "\n",
    "#Order -> Product\n",
    "contains_edges = (df\n",
    "    .select(\n",
    "        X.col(\"order_id\"),\n",
    "        hcol(\"product\",\"category\").alias(\"product_id\"),\n",
    "        X.col(\"quantity\").cast(\"int\").alias(\"qty\")\n",
    "    )\n",
    ")\n",
    "contains_edges.show(3, False)\n",
    "\n",
    "#Order -> PaymentMethod\n",
    "paid_with_edges = (df\n",
    "    .select(\n",
    "        X.col(\"order_id\"),\n",
    "        X.sha2(F.col(\"payment\"),256).alias(\"payment_id\")\n",
    "    )\n",
    "    .dropDuplicates()\n",
    ")\n",
    "paid_with_edges.show(3, False)\n",
    "\n",
    "#Customer -> City\n",
    "located_in_edges = (customer_nodes.alias(\"c\")\n",
    "    .join(city_nodes.alias(\"ci\"), X.col(\"c.city\") == X.col(\"ci.name\"))\n",
    "    .select(X.col(\"c.customer_id\"), X.col(\"ci.city_id\"))\n",
    "    .dropDuplicates()\n",
    ")\n",
    "located_in_edges.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a68775",
   "metadata": {},
   "source": [
    "# Writing Data in Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01d7a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 Customer nodes wrote in Neo4j\n",
      "10 City nodes wrote in Neo4j\n",
      "10 Product nodes wrote in Neo4j\n",
      "250 Order nodes wrote in Neo4j\n",
      "5 PaymentMethod nodes wrote in Neo4j\n",
      "250 PLACED edges wrote in Neo4j\n",
      "250 CONTAINS edges wrote in Neo4j\n",
      "250 PAID_WITH edges wrote in Neo4j\n",
      "92 LOCATED_IN edges wrote in Neo4j\n"
     ]
    }
   ],
   "source": [
    "# Add the code to write a graph from PySpark's DataFrames to Neo4j\n",
    "#Conexion\n",
    "neo4j_url   = \"bolt://neo4j-iteso:7687\"  \n",
    "neo4j_user  = \"neo4j\"\n",
    "neo4j_passw = \"neo4j@1234\"\n",
    "\n",
    "#Nodos\n",
    "\n",
    "#Customer\n",
    "customer_nodes.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"labels\", \":Customer\") \\\n",
    "  .option(\"node.keys\", \"customer_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{customer_nodes.count()} Customer nodes wrote in Neo4j\")\n",
    "\n",
    "#City\n",
    "city_nodes.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"labels\", \":City\") \\\n",
    "  .option(\"node.keys\", \"city_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{city_nodes.count()} City nodes wrote in Neo4j\")\n",
    "\n",
    "#Product\n",
    "product_nodes.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"labels\", \":Product\") \\\n",
    "  .option(\"node.keys\", \"product_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{product_nodes.count()} Product nodes wrote in Neo4j\")\n",
    "\n",
    "#Order\n",
    "order_nodes.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"labels\", \":Order\") \\\n",
    "  .option(\"node.keys\", \"order_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{order_nodes.count()} Order nodes wrote in Neo4j\")\n",
    "\n",
    "#PaymentMethod\n",
    "payment_nodes.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"labels\", \":PaymentMethod\") \\\n",
    "  .option(\"node.keys\", \"payment_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{payment_nodes.count()} PaymentMethod nodes wrote in Neo4j\")\n",
    "\n",
    "\n",
    "#Relaciones\n",
    "\n",
    "#(Customer)-[:PLACED]->(Order)\n",
    "placed_edges.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"relationship\", \"PLACED\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Customer\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"customer_id:customer_id\") \\\n",
    "  .option(\"relationship.target.labels\", \":Order\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"order_id:order_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{placed_edges.count()} PLACED edges wrote in Neo4j\")\n",
    "\n",
    "#(Order)-[:CONTAINS {qty}]->(Product)\n",
    "contains_edges.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"relationship\", \"CONTAINS\") \\\n",
    "  .option(\"relationship.properties\", \"qty:qty\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Order\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"order_id:order_id\") \\\n",
    "  .option(\"relationship.target.labels\", \":Product\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"product_id:product_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{contains_edges.count()} CONTAINS edges wrote in Neo4j\")\n",
    "\n",
    "#(Order)-[:PAID_WITH]->(PaymentMethod)\n",
    "paid_with_edges.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"relationship\", \"PAID_WITH\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Order\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"order_id:order_id\") \\\n",
    "  .option(\"relationship.target.labels\", \":PaymentMethod\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"payment_id:payment_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{paid_with_edges.count()} PAID_WITH edges wrote in Neo4j\")\n",
    "\n",
    "#(Customer)-[:LOCATED_IN]->(City)\n",
    "located_in_edges.write \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .mode(\"Overwrite\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"relationship\", \"LOCATED_IN\") \\\n",
    "  .option(\"relationship.save.strategy\", \"keys\") \\\n",
    "  .option(\"relationship.source.labels\", \":Customer\") \\\n",
    "  .option(\"relationship.source.node.keys\", \"customer_id:customer_id\") \\\n",
    "  .option(\"relationship.target.labels\", \":City\") \\\n",
    "  .option(\"relationship.target.node.keys\", \"city_id:city_id\") \\\n",
    "  .save()\n",
    "\n",
    "print(f\"{located_in_edges.count()} LOCATED_IN edges wrote in Neo4j\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30287ea",
   "metadata": {},
   "source": [
    "# Read and Query Graphs with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03ca7b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|city         |revenue|\n",
      "+-------------+-------+\n",
      "|Miami        |31700.0|\n",
      "|Denver       |29785.0|\n",
      "|Houston      |28390.0|\n",
      "|Dallas       |27145.0|\n",
      "|Seattle      |26890.0|\n",
      "|Boston       |26170.0|\n",
      "|Chicago      |20810.0|\n",
      "|New York     |18940.0|\n",
      "|Los Angeles  |17820.0|\n",
      "|San Francisco|16195.0|\n",
      "+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add the code to read a data frame from Neo4J and run a simple query to verify \n",
    "#Ciudades con mas ventas\n",
    "cypher_city = spark.read \\\n",
    "  .format(\"org.neo4j.spark.DataSource\") \\\n",
    "  .option(\"url\", neo4j_url) \\\n",
    "  .option(\"authentication.basic.username\", neo4j_user) \\\n",
    "  .option(\"authentication.basic.password\", neo4j_passw) \\\n",
    "  .option(\"query\", \"\"\"\n",
    "    MATCH (c:Customer)-[:LOCATED_IN]->(ci:City)\n",
    "    MATCH (c)-[:PLACED]->(o:Order)\n",
    "    RETURN ci.name AS city, sum(o.total_sales) AS revenue\n",
    "    ORDER BY revenue DESC\n",
    "  \"\"\") \\\n",
    "  .load()\n",
    "\n",
    "cypher_city.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078a7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf147f-6503-4a21-ae8e-e1016320f91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
